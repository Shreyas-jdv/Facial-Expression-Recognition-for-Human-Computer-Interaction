# Facial Expression Recognition for Human-Computer Interaction

## Overview

This project aims to create a system that uses Support Vector Machines (SVM) and Decision Trees to recognize facial expressions from images and classify them into different emotional states such as happy, sad, and angry. The system can be integrated into applications like virtual assistants or interactive gaming to enhance user interactions based on their emotional state.

## Key Features

- **SVM for Binary Classification**: Classify expressions as positive or negative emotions.
- **Decision Trees for Multi-Class Classification**: Classify specific emotions like happy, sad, angry, etc.
- **Feature Extraction**: Capture key facial landmarks from images.
- **Real-Time Video Processing**: Detect emotions from live video feeds.

## Installation

### Prerequisites

- Python 3.6 or higher
- Required libraries: `tensorflow`, `scikit-learn`, `opencv-python`, `pandas`, `numpy`, `matplotlib`, `seaborn`


### Datasets to train and test this model

1. FER2013 (Facial Expression Recognition)

2. CK+ (Extended Cohn-Kanade Dataset)

3. AffectNet

4. Facial Expression Recognition 2023

5. SFEW (Static Facial Expressions in the Wild)


### Installing Dependencies

```bash
pip install tensorflow scikit-learn opencv-python pandas numpy matplotlib seaborn
